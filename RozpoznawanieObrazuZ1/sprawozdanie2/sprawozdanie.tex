% vim:encoding=utf8 ft=tex sts=2 sw=2 et:

\documentclass{classrep}
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage{graphicx}
\usepackage{float}

\studycycle{Informatyka, studia dzienne, mgr II st.}
\coursesemester{II}

\coursename{Rozpoznawanie obrazów}
\courseyear{2017/2018}

\courseteacher{dr inż. Bartłomiej Stasiak}
\coursegroup{wtorek, 12:00}

\author{
  \studentinfo{Hubert Marcinkowski}{214942} \and
  \studentinfo{Artur Wróblewski}{214985}
}

\title{Zadanie 2}

\begin{document}
\maketitle


\section{Cel}
Zadanie polegało na implementacji dodatkowej metody klasyfikacji w istniejącym już szkielecie z zadania nr 1. Dodatkowo należało dokonać analizy zdolności klasyfikacji obu metod wykorzystując obrazy z różnymi teksturami. Konieczne było również wprowadzenie dwóch metod ekstrakcji cech: w dziedzinie czasu oraz w dziedzinie częstotliwości.


\section{Zestawy cech}

\subsection{Dziedzina częstotliwości}

Dla dziedziny częstotliwości zaproponowaliśmy użycie 4 cech. Każda z nich bazowała na sumie jasności pikseli w widmie amplitudowym z maską w kształcie pierścienia o promieniach (wewnętrzny i zewnętrzny):
\begin{itemize}
\item 2$px$ i 4$px$
\item 8$px$ i 10$px$
\item 14$px$ i 16$px$
\item 25$px$ i 27$px$
\end{itemize}

Były to dobrze nam znane filtry pasmowoprzepustowe. Wybierając promienie pierścieni kierowaliśmy się występowaniem najjaśniejszych składowych widma. Cechy te są niezależne od obrotu.

\subsection{Dziedzina czasu}

Dla dziedziny czasu zaproponowaliśmy użycie 8 cech:

\begin{itemize}
\item suma jasności pikseli po wykryciu krawędzi z wykorzystaniem operatora Laplace'a
\item 7 momentów obrazu przedstawionych poniżej
\end{itemize}

Momentów obiektu (obrazu), a dokładnie niezmienniki przekształceń. Metoda ta pozwala na rozpoznawanie wzorów  niezależnie od pozycji, rozmiaru czy obrotu. Jako cechy użyliśmy każdego z niezmienników (łącznie 7 cech) - wzory podajemy poniżej:\\

$I_1 = \eta_{20} + \eta_{02}$

$I_2 = (\eta_{20} - \eta_{02})^2 + 4\eta_{11}^2$

$I_3 = (\eta_{30} - 3\eta_{12})^2 + (3\eta_{21} - \eta_{03})^2$

$ I_4 = (\eta_{30} + \eta_{12})^2 + (\eta_{21} + \eta_{03})^2$

$ I_5 = (\eta_{30} - 3\eta_{12}) (\eta_{30} + \eta_{12})[ (\eta_{30} + \eta_{12})^2 - 3 (\eta_{21} + \eta_{03})^2] + (3 \eta_{21} - \eta_{03}) (\eta_{21} + \eta_{03})[ 3(\eta_{30} + \eta_{12})^2 -  (\eta_{21} + \eta_{03})^2]$

$I_6 =  (\eta_{20} - \eta_{02})[(\eta_{30} + \eta_{12})^2 - (\eta_{21} + \eta_{03})^2] + 4\eta_{11}(\eta_{30} + \eta_{12})(\eta_{21} + \eta_{03})$

$I_7 = (3 \eta_{21} - \eta_{03})(\eta_{30} + \eta_{12})[(\eta_{30} + \eta_{12})^2 - 3(\eta_{21} + \eta_{03})^2] - (\eta_{30} - 3\eta_{12})(\eta_{21} + \eta_{03})[3(\eta_{30} + \eta_{12})^2 - (\eta_{21} + \eta_{03})^2]$


\subsection{Wyniki}
\begin{table}[h!]
  \centering
  \caption{Wyniki jakości klasyfikacji oraz czasu obliczeń k-NN dla bazy MNIST dla różnych wartości $k$}
  \label{tab:tab1}
  \begin{tabular}{|c|c|c|}
    \hline
	k & jakość & czas[s]\\
    \hline
	1 & 73.67 & 69.783\\
    \hline
	3 & 76.08 & 67.983\\
	\hline
	5 & 77.90 & 68.175\\
	\hline
	7 & 78.01 & 68.076\\
	\hline
	9 & 78.31 & 67.515\\
	\hline
	11 & 78.58 & 68.414\\
	\hline
	13 & 78.26 & 67.970\\
	\hline
	15 & 77.94 & 67.725\\
	\hline
	19 & 78.00 & 67.416\\
	\hline
	35 & 77.54 & 67.814\\
	\hline
	99 & 75.70 & 68.476\\
	\hline
  \end{tabular}
\end{table}

\begin{table}[h!]
  \centering
  \caption{Wyniki jakości klasyfikacji k-NN dla bazy MNIST dla różnego zestawu cech}
  \label{tab:tab1}
  \begin{tabular}{|c|c|}
    \hline
	wybrane cechy & jakość\\
    \hline
	1 & 21.19\\
    \hline
	2 & 21.69\\
	\hline
	3 & 18.96\\
	\hline
	4 & 17.19\\
	\hline
	5 & 18.86\\
	\hline
	6 & 21.54\\
	\hline
	7 & 24.84\\
	\hline
	8 & 22.58\\
	\hline
	7,8 & 35.62\\
	\hline
	3,4 & 29.54\\
	\hline
	1,2,6,7,8 & 66.97\\
	\hline
	1,3,4,5,6 & 65.59\\
	\hline
	3,4,5,6,7 & 67.26\\
	\hline
	3,4,5,6,8 & 63.99\\
	\hline
  \end{tabular}
\end{table}

\begin{table}[h!]
  \centering
  \caption{Macierz pomyłek k-NN dla bazy MNIST dla wszystkich cech oraz $k=11$}
  \label{tab:tab1}
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
    \hline
	. & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & success ratio \\
    \hline
	0 & 925 & 0 & 15 & 3 & 11 & 1 & 3 & 0 & 18 & 4 & 94.38\\
    \hline
	1 & 0 & 1086 & 8 & 7 & 4 & 5 & 4 & 0 & 16 & 5 & 95.68\\
	\hline
	2 & 32 & 11 & 633 & 186 & 20 & 78 & 29 & 15 & 25 & 3 & 61.33\\
	\hline
	3 & 25 & 16 & 103 & 719 & 1 & 33 & 7 & 45 & 45 & 16 & 71.18\\
	\hline
	4 & 20 & 13 & 27 & 2 & 772 & 18 & 8 & 6 & 10 & 106 & 78.81\\
	\hline
	5 & 19 & 11 & 80 & 102 & 13 & 506 & 30 & 33 & 87 & 11 & 56.72\\
	\hline
	6 & 6 & 8 & 21 & 3 & 6 & 23 & 885 & 0 & 6 & 0 & 92.38\\
	\hline
	7 & 2 & 36 & 10 & 24 & 15 & 25 & 0 & 818 & 26 & 72 & 79.57\\
	\hline
	8 & 87 & 5 & 18 & 31 & 23 & 39 & 9 & 13 & 701 & 48 & 71.97\\
	\hline
	9 & 18 & 14 & 4 & 18 & 47 & 12 & 3 & 41 & 39 & 813 & 80.57\\    
    \hline
  \end{tabular}
\end{table}


\begin{table}[h!]
  \centering
  \caption{Wyniki jakości klasyfikacji oraz czasu obliczeń k-NN dla bazy STaR dla różnych wartości $k$}
  \label{tab:tab1}
  \begin{tabular}{|c|c|c|}
    \hline
	k & jakość & czas[s]\\
    \hline
	1 & 24.66 & 10.549\\
    \hline
	3 & 28.66 & 4.333\\
	\hline
	5 & 30.66 & 4.248\\
	\hline
	7 & 32.00 & 4.247\\
	\hline
	9 & 34.00 & 4.274\\
	\hline
	11 & 34.66 & 4.338\\
	\hline
	13 & 32.66 & 4.431\\
	\hline
	15 & 29.33 & 4.257\\
	\hline
	31 & 29.33 & 4.279\\
	\hline
	99 & 24.00 & 4.248\\
	\hline
  \end{tabular}
\end{table}

\section{Wnioski}

Wyniki dla bazy MNIST przy użyciu jedynie 8 cech są zadowalające. Dodatkowo czasy przetwarzania 10 000 elementów są relatywnie krótkie. Parametr $k$ nie wpływa w naszej implementacji na czas wykonania obliczeń - jedynie na jakość klasyfikacji. Tutaj warto zauważyć, że wraz ze wzrostem $k$ klasyfikator zwracał większa liczbę poprawnych wyników, aczkolwiek wynik najlepszy osiągnęliśmy przy $k=11$: $78.58\%$. Zwiększając coraz bardziej $k$ wynik staje się tylko gorszy. Wybór oraz zdefiniowanie odpowiedniego zestawu cech jest kluczowy przy tym rodzaju klasyfikacji. Mając jednak ich w tym przypadku 8 bardzo ciężko jest wybrać te, które wpłyną na osiągnięcie najlepszego wyniku. Postanowiliśmy sprawdzić to porównując różne zestawy: złożone z najlepszych statystycznie cech oraz tych najgorszych. Możemy powiedzieć, że jeśli istnieje jakiś związek między cechami, a końcową jakością klasyfikacji to będzie to raczej ilość użytych cech, niż fakt użycia najlepszych statystycznie (tu: uzyskujących najlepsze wyniki przy skorzystaniu tylko z jednej cechy). Analizując macierz pomyłek możemy zauważyć, że klasyfikator najlepiej sobie poradził z cyframi 1, 0 i 6 uzyskując wynik ponad $92\%$ dla każdej. Powyżej $70\%$ były kolejno 9, 7, 4, 8 oraz 3. Najgorzej wypadło rozpoznawanie cyfr 2 i 5 (poniżej $65\%$). Warto zauważyć, że najczęściej błędnie były klasyfikowane jako cyfra 3. Możliwe, że przez podobieństwo górnej połowy (do cyfry 2) oraz dolnej (do cyfry 5).

Inaczej ma się niestety sytuacja dla bazy STAR. Dla $k = 11$ uzyskaliśmy najlepszy wynik, aczkolwiek wynosi on niewiele ponad $34\%$. Dalej jest to pozytywny wynik, gdyż osiągnęliśmy 3 razy większą dokładność niż w przypadku gdybyśmy użyli do klasyfikacji funkcji losowej. Czas przeznaczony na samą klasyfikację obiektów znacznie się zmniejszył w stosunku do MNIST, gdyż operowaliśmy na mniejszym zbiorze danych. Zwiększeniu uległ jednak czas przypisywania odpowiednich cech, gdyż wykorzystane operacje na obrazie takie jak podwójna filtracja przeprowadzane są dla każdego obrazka. Klasyfikatorowi nie udało się przypisać dwóch z dziesięciu klas, największą zaś skuteczność otrzymał dla klasy dziewiątej ($86\%$), którą to oznaczyliśmy zdjęcia sznurka.
Zaskakującym okazał się fakt, iż wykorzystanie momentów Hu nie spowodowało gwałtownego wzrostu w ilości zaklasyfikowanych obiektów. Nie pomogła tu też znacząco normalizacja danych, gdyż zwiększyła ona wyniki zaledwie o parę procent. 

\end{document}
